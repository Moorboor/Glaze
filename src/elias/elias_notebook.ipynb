{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Implementation, partly still: Implementation Plan (Detailed; Must Follow MODEL-COMPARISON LOCK)\n",
    "\n",
    "This section is the executable plan for the analysis workflow. The `MODEL-COMPARISON LOCK` section is the source of truth for assumptions, scoring, and inference rules.\n",
    "\n",
    "## 0) Scope and constraints [x]\n",
    "\n",
    "- [x] Scope is non-hierarchical, participant-wise fitting (`P01`, `P02`, `P03`).\n",
    "- [x] Compare exactly 3 candidate models:\n",
    "  1. Model A: DNM + CNM (blockwise threshold)\n",
    "  2. Model B: DNM + CNM (blockwise asymptote)\n",
    "  3. Model C: DNM + DDM (start from `psi`, drift from `LLR`)\n",
    "- [x] Primary target is joint prediction of `choice` and `rt`.\n",
    "- [x] Winner selection uses TEST joint score only (as locked).\n",
    "\n",
    "## 1) Notebook setup and reproducibility\n",
    "\n",
    "- [ ] Add one setup code cell that:\n",
    "  1. Loads `src/elias/elias_ddm.py`.\n",
    "  2. Imports `numpy`, `pandas`, `matplotlib`, `scipy`.\n",
    "  3. Sets global constants from lock:\n",
    "     - `DT = 0.001`\n",
    "     - `T_MAX = 5.0`\n",
    "     - `N_SIMS_PER_TRIAL = 2000`\n",
    "     - `RT_BIN_WIDTH = 0.02`\n",
    "     - `EPS = 1e-12`\n",
    "     - `SEED = 0`\n",
    "  4. Initializes deterministic RNG policy (fixed seeds logged per participant/model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats  # optional; keep scipy imported for later steps\n",
    "\n",
    "# Resolve repo root robustly\n",
    "repo_root = Path.cwd().resolve()\n",
    "if not (repo_root / \"src\").exists() and (repo_root.parent / \"src\").exists():\n",
    "    repo_root = repo_root.parent\n",
    "\n",
    "# Make src/elias importable\n",
    "elias_src = repo_root / \"src\" / \"elias\"\n",
    "if str(elias_src) not in sys.path:\n",
    "    sys.path.insert(0, str(elias_src))\n",
    "\n",
    "# Direct imports from elias_ddm.py\n",
    "from elias_ddm import (\n",
    "    load_participant_data,\n",
    "    run_model_a_threshold,\n",
    "    run_model_b_asymptote,\n",
    "    run_model_c_ddm,\n",
    "    run_all_models_for_participant,\n",
    ")\n",
    "\n",
    "# Locked constants\n",
    "DT = 0.001\n",
    "T_MAX = 5.0\n",
    "N_SIMS_PER_TRIAL = 2000\n",
    "RT_BIN_WIDTH = 0.02\n",
    "EPS = 1e-12\n",
    "SEED = 0\n",
    "\n",
    "print(\"Setup complete.\")\n",
    "print(f\"repo_root = {repo_root}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2) Data load, QC, exclusions, and split\n",
    "\n",
    "- [ ] Add one data-prep code cell that:\n",
    "  1. Loads all participants with `load_participant_data(...)`.\n",
    "  2. Converts RT from ms to seconds exactly once.\n",
    "  3. Applies locked exclusions:\n",
    "     - drop missing `choice` or RT\n",
    "     - drop RT < 0.150 s\n",
    "     - drop RT > 5.000 s\n",
    "  4. Verifies expected structure per participant:\n",
    "     - 4 blocks\n",
    "     - nominally 40 trials per block before exclusions\n",
    "  5. Creates split labels per block:\n",
    "     - TRAIN: trials 1-30\n",
    "     - TEST: trials 31-40\n",
    "  6. Saves QC table (`participant`, `block`, `n_train`, `n_test`, `n_dropped`).\n",
    "\n",
    "## 3) Unified simulation-to-likelihood interface\n",
    "\n",
    "- [ ] Add helper code cells implementing one common scoring interface for all models.\n",
    "- [ ] For each trial, estimate from simulations:\n",
    "  1. `p(choice_t)`\n",
    "  2. `p(rt_t | choice_t)` via histogram density (`0.02 s` bins + `EPS` smoothing)\n",
    "- [ ] Trial joint negative log score:\n",
    "  - `L_t = -log p(choice_t) - log p(rt_t | choice_t)`\n",
    "- [ ] Return all three aggregates:\n",
    "  1. joint score (primary)\n",
    "  2. choice-only score\n",
    "  3. RT-only conditional score\n",
    "\n",
    "## 4) Model parameterization and bounds (participant-wise)\n",
    "\n",
    "- [ ] Define explicit parameter vectors and transforms.\n",
    "\n",
    "### Model A parameters (fit on TRAIN)\n",
    "- [ ] `theta_A = [thr_b1, thr_b2, thr_b3, thr_b4, t0, g]`\n",
    "- [ ] Constrain thresholds positive and `t0` in valid range.\n",
    "- [ ] `g` is a global evidence/noise gain for participant.\n",
    "\n",
    "### Model B parameters (fit on TRAIN)\n",
    "- [ ] `theta_B = [asy_b1, asy_b2, asy_b3, asy_b4, t0, g]`\n",
    "- [ ] Constrain asymptotes positive and `t0` in valid range.\n",
    "\n",
    "### Model C parameters (fit on TRAIN)\n",
    "- [ ] `theta_C = [a, t0, k_v, k_z]`\n",
    "- [ ] Fix diffusion scale `s = 1.0`.\n",
    "- [ ] Use mapping from lock:\n",
    "  - `x0_t = k_z * psi_t`\n",
    "  - `v_t = k_v * LLR_t`\n",
    "\n",
    "## 5) Fitting procedure (TRAIN only)\n",
    "\n",
    "- [ ] Use one optimizer protocol for all models:\n",
    "  1. Multi-start optimization (same number of starts per model).\n",
    "  2. Same convergence criteria and max iterations.\n",
    "  3. Same seed policy for simulation-based likelihood evaluation.\n",
    "- [ ] Fit independently for each participant.\n",
    "- [ ] Save full fit artifacts:\n",
    "  - best params\n",
    "  - best TRAIN joint score\n",
    "  - optimizer status and iterations\n",
    "  - per-start results\n",
    "\n",
    "## 6) TEST evaluation and winner decision\n",
    "\n",
    "- [ ] Evaluate fitted params on TEST only.\n",
    "- [ ] Compute per participant:\n",
    "  1. TEST joint score by block\n",
    "  2. TEST joint score total (sum over 4 blocks)\n",
    "  3. TEST choice-only and RT-only totals (secondary)\n",
    "- [ ] Apply locked participant-level winner rule:\n",
    "  1. best TEST joint total\n",
    "  2. best in >= 3/4 blocks\n",
    "  3. block-bootstrap CI for DeltaScore(best - runner-up) strictly > 0\n",
    "- [ ] Apply locked group rule:\n",
    "  - same model is clear winner in >= 2/3 participants\n",
    "  - otherwise report heterogeneity/inconclusive\n",
    "\n",
    "## 7) Mandatory validity checks (after winner logic)\n",
    "\n",
    "- [ ] Posterior predictive checks per participant and block:\n",
    "  1. RT distribution overlay (data vs simulated)\n",
    "  2. RT quantile comparison (10/30/50/70/90)\n",
    "  3. accuracy by block\n",
    "- [ ] Change-point/hazard signatures:\n",
    "  1. RT and accuracy near change-point vs late block\n",
    "  2. dependence on prior strength `|psi|`\n",
    "- [ ] Model recovery:\n",
    "  1. simulate surrogate data from each fitted model\n",
    "  2. refit all models\n",
    "  3. summarize recovery matrix and distinguishability\n",
    "\n",
    "## 8) Deliverables and export\n",
    "\n",
    "- [ ] Export participant-level result table:\n",
    "  - fitted params per model\n",
    "  - TRAIN and TEST scores\n",
    "  - winner/inconclusive status\n",
    "- [ ] Export block-level table for bootstrap and consistency checks.\n",
    "- [ ] Save all diagnostic plots used in report.\n",
    "- [ ] Write concise conclusion text strictly following lock interpretation mapping.\n",
    "\n",
    "## 9) Definition of done\n",
    "\n",
    "- [ ] All lock constraints are satisfied exactly.\n",
    "- [ ] Winner decision is reproducible from saved tables and seed logs.\n",
    "- [ ] Mandatory validity checks are present for every participant.\n",
    "- [ ] If model recovery is weak, final claim is explicitly downgraded to weak/inconclusive evidence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# MODEL-COMPARISON LOCK (Triangle task; P01–P03; 4 blocks × 40 trials)\n",
    "\n",
    "## Goal (what I may conclude)\n",
    "I will conclude only: “Among these candidate models, under the pre-specified scoring + held-out evaluation + checks, model X provides the best predictive account of choice+RT in this dataset.”\n",
    "I will NOT conclude: “X is the true brain model.”\n",
    "\n",
    "---\n",
    "\n",
    "## Data + preprocessing (fixed)\n",
    "- Observables (targets): \n",
    "  1) `choice_t` (binary) \n",
    "  2) `rt_t` (continuous; seconds)\n",
    "- Inputs (given to models): `LLR_t`, hazard/block info, and any DNM-derived `psi_t` if applicable.\n",
    "- Exclusion rules (apply identically to all models):\n",
    "  - drop trials with missing choice or RT\n",
    "  - drop RT < 0.150 s or RT > 5.000 s\n",
    "- Units: convert RT ms → seconds once, then keep seconds everywhere.\n",
    "\n",
    "---\n",
    "\n",
    "## Candidate models (fixed)\n",
    "Model A: **DNM + CNM (blockwise threshold)**\n",
    "- DNM provides trial-wise belief/prior quantities (e.g., `psi_t`) from hazard + evidence.\n",
    "- CNM uses a **block-specific threshold** parameter to generate choice+RT distribution.\n",
    "\n",
    "Model B: **DNM + CNM (blockwise asymptote)**\n",
    "- Same DNM inputs.\n",
    "- CNM uses a **block-specific asymptote (non-absorbing stabilization)** parameter to generate choice+RT distribution.\n",
    "\n",
    "Model C: **DNM + DDM (standard bounded diffusion)**\n",
    "- Map DNM outputs to DDM per trial:\n",
    "  - start point: `x0_t = k_z * psi_t`\n",
    "  - drift: `v_t = k_v * LLR_t`\n",
    "  - bounds: ±a, nondecision time: t0, diffusion scale fixed (see below).\n",
    "\n",
    "(If any mapping differs, that becomes a separate model and must be reported as such.)\n",
    "\n",
    "---\n",
    "\n",
    "## Fit vs fixed parameters (locked)\n",
    "Numerical hyperparameters (fixed for all models):\n",
    "- `dt = 0.001 s`, `t_max = 5.0 s`, `n_sims_per_trial = 2000`\n",
    "- RNG: seeded and logged (default seed=0); same seed policy for all models.\n",
    "- RT density for likelihood: histogram density with bin width `0.02 s` (20 ms) + epsilon smoothing `1e-12`.\n",
    "\n",
    "Model parameters to fit **per participant** (fit on TRAIN only):\n",
    "- Model A: 4 block params (threshold per block) + `t0` + one evidence/noise gain (single global).\n",
    "- Model B: 4 block params (asymptote per block) + `t0` + one evidence/noise gain (single global).\n",
    "- Model C (DDM): `a`, `t0`, `k_v`, `k_z`; diffusion scale fixed `s=1.0` (identifiability).\n",
    "\n",
    "---\n",
    "\n",
    "## Primary evaluation protocol (locked)\n",
    "Train/test split (forward-chaining; preserves sequential dependence):\n",
    "- For each block (40 trials):\n",
    "  - TRAIN = trials 1–30\n",
    "  - TEST  = trials 31–40\n",
    "- Fit parameters on TRAIN only; evaluate scores on TEST only.\n",
    "- Aggregate TEST scores across the 4 blocks per participant.\n",
    "\n",
    "History usage:\n",
    "- PRIMARY scoring uses one-step-ahead prediction: condition on observed history up to t−1 (if a model uses it).\n",
    "- SECONDARY validation uses free-running simulations (model feeds itself its own simulated history).\n",
    "\n",
    "---\n",
    "\n",
    "## Primary scoring rule (locked)\n",
    "For each trial t in TEST:\n",
    "- Joint negative log score:\n",
    "  - `L_t = -log p(choice_t)  -log p(rt_t | choice_t)`\n",
    "- `p(choice_t)` and `p(rt_t | choice_t)` are estimated from model simulations (same n_sims, dt, seed rules).\n",
    "Total score per participant = sum over TEST trials across all 4 blocks.\n",
    "Report also (but do NOT use for winner selection):\n",
    "- choice-only score = sum `-log p(choice_t)`\n",
    "- RT-only conditional score = sum `-log p(rt_t | choice_t)`\n",
    "\n",
    "Winner selection uses ONLY the joint score.\n",
    "\n",
    "---\n",
    "\n",
    "## “Winner” vs “inconclusive” rules (locked)\n",
    "Per participant:\n",
    "- A model is a clear winner if:\n",
    "  1) it has the best TEST joint score overall, AND\n",
    "  2) it is best in ≥ 3 of 4 blocks (blockwise consistency), AND\n",
    "  3) block-bootstrap over the 4 blocks gives ΔScore(best − runner-up) > 0 with 95% CI strictly > 0.\n",
    "Otherwise: “no clear winner” for that participant.\n",
    "\n",
    "Group-level (P01–P03):\n",
    "- Only claim a group preference if the same model is a clear winner in ≥ 2 of 3 participants.\n",
    "Otherwise: report heterogeneity / inconclusive.\n",
    "\n",
    "---\n",
    "\n",
    "## Mandatory validity checks (must be shown regardless of winner)\n",
    "1) Posterior predictive checks (per participant; per block):\n",
    "   - RT distribution overlay (data vs simulated)\n",
    "   - RT quantiles (10/30/50/70/90%)\n",
    "   - accuracy by block\n",
    "2) Change-point / hazard signatures (as plots):\n",
    "   - accuracy & RT near change-point vs later steady-state\n",
    "   - dependence of RT/choice on prior strength |psi| (if DNM present)\n",
    "3) Model recovery (surrogate data):\n",
    "   - simulate datasets from each fitted model; refit all models; check if generating model is recovered above chance.\n",
    "   - If recovery is poor, interpret any real-data “winner” as weak evidence (models not distinguishable here).\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation mapping (locked)\n",
    "If Model A wins: bounded/thresholded continuous accumulation with blockwise caution provides best predictive account.\n",
    "If Model B wins: non-absorbing stabilization/asymptote mechanism better captures behavior than strict bound crossing.\n",
    "If Model C wins: standard DDM driven by trial-wise prior (start) + evidence (drift) is sufficient; extra CNM nonlinearity not supported by prediction here.\n",
    "If inconclusive: dataset (3 participants; 4 blocks) does not disambiguate these mechanisms under the locked protocol; report equivalence and what data would be needed (more participants/blocks or stronger manipulations).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
