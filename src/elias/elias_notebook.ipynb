{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ORDER OF MODELING STEPS\n",
    "\n",
    "\n",
    "This notebook follows the modeling framework outlined below.\n",
    "1. Conceptualize Model (What do I want to model and why?)\n",
    "2. Build model (figure out equations, write code)\n",
    "3. Fit model to surrogate data (parameter and model recovery)\n",
    "\n",
    "**CHECKPOINT: Only continue if the model and experiment can answer the question in theory, and if parameters and model are recoverable**\n",
    "\n",
    "4. Fit model to participant data(1. parameter and model fit, 2. validate model)\n",
    "\n",
    "**CHECKPOINT: only continue if the model can account for data.**\n",
    "5. latent variable analysis and report results\n",
    "\n",
    "Based on Prof. Musslick’s lecture slides in his class about cognitive modeling in the winter semester 2024.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## STEP 1) CONCEPTUALIZE MODEL — LOCK + CHECKLIST\n",
    "\n",
    "### Locked intent and claim boundaries\n",
    "- [x] Target claim: \"Among the candidate models, under the pre-specified scoring + held-out evaluation + checks, model X best predicts choice+RT in this dataset.\"\n",
    "- [x] Non-claim boundary: \"X is the true brain model\" is out of scope.\n",
    "- [x] Scope is participant-wise (`P01`, `P02`, `P03`) with three candidate models.\n",
    "\n",
    "### Locked hazard input interpretation\n",
    "- [x] Hazard input is fixed to `subjective_h_snapshot`.\n",
    "- [x] Constraint: treat hazard input as past-only / externally fixed during fit and evaluation.\n",
    "- [x] Required caveat sentence remains mandatory in final reporting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## STEP 2A) BUILD MODEL — LOCKED SETUP SPEC + CHECKLIST\n",
    "\n",
    "### Locked candidate models\n",
    "- [x] Model A: DNM + CNM (blockwise threshold).\n",
    "- [x] Model B: DNM + CNM (blockwise asymptote).\n",
    "- [x] Model C: DNM + DDM (`x0_t = k_z * psi_t`, `v_t = k_v * LLR_t`).\n",
    "\n",
    "### Locked numerical policy\n",
    "- [x] `DT = 1 ms`\n",
    "- [x] `T_MAX = 5000 ms`\n",
    "- [x] `N_SIMS_PER_TRIAL = 2000`\n",
    "- [x] `RT_BIN_WIDTH = 20 ms`\n",
    "- [x] `EPS = 1e-12`\n",
    "- [x] Deterministic seed policy is fixed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2A — SETUP, IMPORTS, PATHS, AND LOCKED CONSTANTS\n",
    "\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import sys\n",
    "from typing import Final\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Resolve repository root so notebook paths work from different launch folders.\n",
    "REPO_ROOT = Path.cwd().resolve().parent.parent\n",
    "if not (REPO_ROOT / \"src\").exists() and (REPO_ROOT.parent / \"src\").exists():\n",
    "    REPO_ROOT = REPO_ROOT.parent\n",
    "\n",
    "# Add `src/` and `src/elias/` to the import path for local modules.\n",
    "SRC_ROOT = REPO_ROOT / \"src\"\n",
    "ELIAS_SRC = SRC_ROOT / \"elias\"\n",
    "for import_path in (SRC_ROOT, ELIAS_SRC):\n",
    "    if str(import_path) not in sys.path:\n",
    "        sys.path.insert(0, str(import_path))\n",
    "\n",
    "# Reload local module so notebook edits are picked up without stale imports.\n",
    "import elias_models as _elias_models\n",
    "importlib.reload(_elias_models)\n",
    "\n",
    "# Import Elias-local preprocessing helpers and model runners.\n",
    "from elias_models import (\n",
    "    load_participant_data,\n",
    "    preprocess_loaded_participant_data,\n",
    "    run_all_models_for_participant,\n",
    "    run_model_a_threshold,\n",
    "    run_model_b_asymptote,\n",
    "    run_model_c_ddm,\n",
    ")\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) Locked hard-coded constants (must match MODEL-COMPARISON LOCK).\n",
    "# Keep these fixed across models/participants for fair comparison.\n",
    "# `elias_models` APIs now use milliseconds directly.\n",
    "\n",
    "\n",
    "# Simulation integration step (DT = delta time) in milliseconds.\n",
    "DT: Final[float] = 1\n",
    "\n",
    "# Maximum allowed RT window per trial in milliseconds.\n",
    "T_MAX: Final[float] = 5000\n",
    "\n",
    "# Monte Carlo samples per trial for probability estimates.\n",
    "N_SIMS_PER_TRIAL: Final[int] = 2000\n",
    "\n",
    "# RT histogram bin width in ms for density scoring.\n",
    "RT_BIN_WIDTH: Final[float] = 20\n",
    "\n",
    "# Small smoothing constant (EPS=epsilon) to avoid log(0) in likelihood terms.\n",
    "EPS: Final[float] = 1e-12\n",
    "\n",
    "# Global base RNG seed for reproducible simulation/scoring.\n",
    "SEED: Final[int] = 0\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"Setup complete.\")\n",
    "print(f\"REPO_ROOT = {REPO_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## STEP 2B) BUILD MODEL — DATA/PREPROCESSING LOCK + CHECKLIST\n",
    "\n",
    "### Locked preprocessing/data rules\n",
    "- [x] Source data uses `data/elias.csv`, `data/evan.csv`, `data/maik.csv` merged into `participants.csv`.\n",
    "- [x] Exclusion rules are fixed: drop missing required values, RT < 150 ms, RT > 5000 ms.\n",
    "- [x] Units remain milliseconds end-to-end.\n",
    "- [x] Split rule is fixed: TRAIN `trial_index <= 30`, TEST `trial_index >= 31`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2B — DATA LOADING, EXCLUSIONS, PREPROCESSING, AND SPLIT LABELS\n",
    "\n",
    "# Use the existing merged participant CSV stored in `data/`.\n",
    "participants_csv_path = REPO_ROOT / \"data\" / \"participants.csv\"\n",
    "\n",
    "# Load participant rows and derive model-ready state columns.\n",
    "df_loaded = load_participant_data(\n",
    "    csv_path=participants_csv_path,\n",
    "    participant_ids=None,\n",
    "    hazard_col=\"subjective_h_snapshot\",\n",
    "    reset_on=(\"participant\", \"block\"),\n",
    ")\n",
    "\n",
    "# Apply shared preprocessing helper to keep this notebook cell concise.\n",
    "prep_outputs = preprocess_loaded_participant_data(\n",
    "    df_loaded,\n",
    "    min_rt_ms=150,\n",
    "    max_rt_ms=5000,\n",
    "    train_trial_max_index=30,\n",
    "    expected_blocks_per_participant=4,\n",
    "    nominal_trials_per_block_before=40,\n",
    ")\n",
    "\n",
    "# Unpack outputs used in later notebook sections.\n",
    "df_all = prep_outputs[\"df_all\"]\n",
    "removed_rows_df = prep_outputs[\"removed_rows_df\"]\n",
    "preprocessing_overview_table = prep_outputs[\"preprocessing_overview_table\"]\n",
    "participant_structure_table = prep_outputs[\"participant_structure_table\"]\n",
    "\n",
    "# Report whether this safety step changed anything.\n",
    "print(f\"Participants CSV path:    {participants_csv_path}\")\n",
    "print(f\"Rows before safety check: {prep_outputs['before_n']}\")\n",
    "print(f\"Rows after safety check:  {prep_outputs['after_n']}\")\n",
    "print(f\"Rows removed:             {prep_outputs['removed_n']}\")\n",
    "print(f\"Safety check changed data: {prep_outputs['safety_check_changed_data']}\")\n",
    "\n",
    "# Show participants still present after exclusions.\n",
    "print(\"\\nParticipants:\\n\", df_all[\"participant_id\"].unique())\n",
    "\n",
    "# Show participant-level structure checks requested in section 2.\n",
    "print(\"\\nParticipant structure checks:\")\n",
    "display(participant_structure_table)\n",
    "\n",
    "# Show preprocessing overview table requested in section 2.\n",
    "print(\"\\nPreprocessing overview table:\")\n",
    "display(preprocessing_overview_table)\n",
    "\n",
    "# Show all rows removed by validity/RT filters for auditability.\n",
    "print(\"\\nRemoved rows (all rows excluded by validity/RT checks):\")\n",
    "display(removed_rows_df)\n",
    "\n",
    "# Show the prepared modeling DataFrame used by downstream cells.\n",
    "print(\"\\nPrepared modeling DataFrame (head):\")\n",
    "display(df_all.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### STEP 2B RESULTS — CURRENT DATA SNAPSHOT\n",
    "\n",
    "- Using the current merged file `data/participants.csv`, the dataset contains `3` participants with `467` rows before exclusions:\n",
    "  - `P01`: `160` rows\n",
    "  - `P02`: `147` rows (short block 1)\n",
    "  - `P03`: `160` rows\n",
    "- Block structure before exclusions:\n",
    "  - `P01`: `40/40/40/40`\n",
    "  - `P02`: `27/40/40/40`\n",
    "  - `P03`: `40/40/40/40`\n",
    "- After locked exclusions (`drop missing required values`, `RT < 150 ms`, `RT > 5000 ms`), `456` rows remain and `11` rows are removed.\n",
    "- Removal reasons in current data:\n",
    "  - `10` rows with `RT > 5000 ms`\n",
    "  - `1` row with `RT < 150 ms`\n",
    "  - `0` rows dropped due to missing/non-finite required values\n",
    "- Participant-level counts after exclusions:\n",
    "  - `P01`: `149/160` kept (`11` dropped)\n",
    "  - `P02`: `147/147` kept (`0` dropped)\n",
    "  - `P03`: `160/160` kept (`0` dropped)\n",
    "- Split consequences with trial-index rule:\n",
    "  - `P02` block 1 yields `17` TRAIN and `10` TEST trials (valid, but fewer TRAIN trials than full blocks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## STEP 2C) BUILD MODEL — UNIFIED SIMULATION-TO-LIKELIHOOD LOCK + CHECKLIST\n",
    "\n",
    "- [x] Common scoring interface is implemented via `score_model_simulation_likelihood(...)`.\n",
    "- [x] Per-trial `p(choice_t)` is estimated from simulations.\n",
    "- [x] Per-trial `p(rt_t | choice_t)` uses histogram density (`20 ms` bins + `EPS` smoothing).\n",
    "- [x] Joint trial score is implemented: `L_t = -log p(choice_t) - log p(rt_t | choice_t)`.\n",
    "- [x] Aggregates returned: joint (primary), choice-only, RT-only conditional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2C — UNIFIED SIMULATION-TO-LIKELIHOOD SCORING DEMO\n",
    "\n",
    "from elias_models import score_model_simulation_likelihood\n",
    "\n",
    "# Verify Elias-local choice encoding after import-time normalization.\n",
    "choice_values = sorted(df_all[\"choice\"].dropna().astype(int).unique().tolist())\n",
    "print(\"Observed choice encoding in df_all:\", choice_values)\n",
    "\n",
    "# Use a compact TEST subset for a fast build-step smoke run.\n",
    "scoring_input_df = df_all[df_all[\"split\"] == \"TEST\"].copy()\n",
    "if scoring_input_df.empty:\n",
    "    scoring_input_df = df_all.copy()\n",
    "scoring_input_df = scoring_input_df.head(12).copy()\n",
    "\n",
    "scoring_configs = {\n",
    "    \"cont_threshold\": {\n",
    "        \"max_duration_ms\": float(T_MAX),\n",
    "        \"dt_ms\": float(DT),\n",
    "    },\n",
    "    \"cont_asymptote\": {\n",
    "        \"max_duration_ms\": float(T_MAX),\n",
    "        \"dt_ms\": float(DT),\n",
    "    },\n",
    "    \"ddm_dnm\": {\n",
    "        \"max_duration_ms\": float(T_MAX),\n",
    "        \"dt_ms\": float(DT),\n",
    "    },\n",
    "}\n",
    "\n",
    "aggregate_rows: list[dict[str, object]] = []\n",
    "trial_scores_by_model: dict[str, pd.DataFrame] = {}\n",
    "\n",
    "for model_name, model_params in scoring_configs.items():\n",
    "    score_output = score_model_simulation_likelihood(\n",
    "        scoring_input_df,\n",
    "        model_name=model_name,\n",
    "        model_params=model_params,\n",
    "        n_sims_per_trial=min(N_SIMS_PER_TRIAL, 200),\n",
    "        rt_bin_width_ms=float(RT_BIN_WIDTH),\n",
    "        rt_max_ms=float(T_MAX),\n",
    "        eps=float(EPS),\n",
    "        random_seed=int(SEED),\n",
    "    )\n",
    "    aggregate_rows.append(score_output[\"aggregate_scores\"])\n",
    "    trial_scores_by_model[model_name] = score_output[\"trial_scores\"]\n",
    "\n",
    "aggregate_scores_table = (\n",
    "    pd.DataFrame(aggregate_rows)\n",
    "    .sort_values(\"joint_score\", ascending=True)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nAggregate simulation-likelihood scores (lower is better):\")\n",
    "display(aggregate_scores_table)\n",
    "\n",
    "for model_name, trial_scores in trial_scores_by_model.items():\n",
    "    print(f\"\\n{model_name} trial-score preview:\")\n",
    "    display(trial_scores.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## STEP 2D) BUILD MODEL — PARAMETERIZATION/BOUNDS LOCK + CHECKLIST\n",
    "\n",
    "- [x] Define explicit parameter vectors and transforms.\n",
    "- [x] Model A: `theta_A = [thr_b1, thr_b2, thr_b3, thr_b4, t0, g]` with valid bounds.\n",
    "- [x] Model B: `theta_B = [asy_b1, asy_b2, asy_b3, asy_b4, t0, g]` with valid bounds.\n",
    "- [x] Model C: `theta_C = [a, t0, k_v, k_z]` with fixed `s = 1.0`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION DECISIONS + DOWNSIDES FOR DISCUSSION/RESULTS\n",
    "\n",
    "- Decision: bounded parameter vectors use logistic box transforms (`eta -> theta`) with finite bounds.\n",
    "- Decision: block parameters use fixed independent order `b1, b2, b3, b4` (no monotonic coupling).\n",
    "- Decision: Step 2D provides `theta -> scorer model_params` mapping now; full blockwise runtime integration remains a later step.\n",
    "- Downside: logistic transforms can saturate near bounds and flatten local gradient information.\n",
    "- Downside: independent block parameters increase flexibility and can increase overfitting risk.\n",
    "- Downside: A/B block sidecars are not consumed by current scorer internals, so block-effect evidence is deferred until integration.\n",
    "- Downside: fixing `s = 1.0` in Model C shifts scale tradeoffs into `a` and `k_v`, reducing direct interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2D — PARAMETERIZATION, BOUNDS, AND SCORER-MAPPING HELPER DEMO\n",
    "\n",
    "from elias_models import (\n",
    "    eta_to_theta,\n",
    "    get_parameter_spec,\n",
    "    theta_to_eta,\n",
    "    theta_to_named_params,\n",
    "    theta_to_scoring_model_params,\n",
    ")\n",
    "\n",
    "model_names = [\"cont_threshold\", \"cont_asymptote\", \"ddm_dnm\"]\n",
    "\n",
    "# Display ordered parameter specifications used by the optimizer/scoring bridge.\n",
    "for model_name in model_names:\n",
    "    print(f\"\\n{model_name} parameter specification:\")\n",
    "    display(pd.DataFrame(get_parameter_spec(model_name)))\n",
    "\n",
    "# Use moderate eta values to validate bounded transform and inverse consistency.\n",
    "eta_examples = {\n",
    "    \"cont_threshold\": np.array([-0.8, -0.2, 0.3, 0.9, -0.4, 0.5], dtype=float),\n",
    "    \"cont_asymptote\": np.array([0.6, -0.4, 0.1, -0.7, 0.2, -0.3], dtype=float),\n",
    "    \"ddm_dnm\": np.array([0.2, -0.5, 0.8, -0.6], dtype=float),\n",
    "}\n",
    "\n",
    "roundtrip_rows: list[dict[str, object]] = []\n",
    "\n",
    "for model_name, eta_vector in eta_examples.items():\n",
    "    theta_vector = eta_to_theta(model_name, eta_vector)\n",
    "    eta_roundtrip = theta_to_eta(model_name, theta_vector)\n",
    "    max_abs_error = float(np.max(np.abs(eta_roundtrip - eta_vector)))\n",
    "\n",
    "    spec_df = pd.DataFrame(get_parameter_spec(model_name))\n",
    "    lower = spec_df[\"lower\"].to_numpy(dtype=float)\n",
    "    upper = spec_df[\"upper\"].to_numpy(dtype=float)\n",
    "    in_bounds = bool(np.all(theta_vector >= lower) and np.all(theta_vector <= upper))\n",
    "\n",
    "    named_params = theta_to_named_params(model_name, theta_vector)\n",
    "    scoring_params = theta_to_scoring_model_params(\n",
    "        model_name,\n",
    "        theta_vector,\n",
    "        block_ids=(1, 2, 3, 4),\n",
    "    )\n",
    "\n",
    "    roundtrip_rows.append(\n",
    "        {\n",
    "            \"model_name\": model_name,\n",
    "            \"theta_dim\": int(theta_vector.size),\n",
    "            \"max_abs_eta_roundtrip_error\": max_abs_error,\n",
    "            \"theta_within_bounds\": in_bounds,\n",
    "            \"scoring_keys\": \", \".join(sorted(scoring_params.keys())),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"\\n{model_name} named parameters:\")\n",
    "    display(pd.DataFrame([named_params]))\n",
    "    print(f\"{model_name} scorer parameter mapping:\")\n",
    "    display(pd.DataFrame([scoring_params]))\n",
    "\n",
    "roundtrip_table = pd.DataFrame(roundtrip_rows)\n",
    "print(\"\\nTransform roundtrip and bounds validation summary:\")\n",
    "display(roundtrip_table)\n",
    "\n",
    "print(\"\\nNote: A/B block sidecars are provided for later optimization/runtime integration and are not consumed by current scorer internals.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## STEP 3) FIT MODEL TO SURROGATE DATA — LOCK + CHECKLIST\n",
    "\n",
    "### Locked checkpoint rule\n",
    "- [ ] Simulate surrogate datasets from each candidate generating model using pseudo-true parameters.\n",
    "\n",
    "### Terminology note\n",
    "- Surrogate recovery starts with broad pseudo-true parameter coverage across Step 2D bounds.\n",
    "- Optional post-Step-4 rerun can narrow ranges using participant-informed fitted distributions.\n",
    "\n",
    "### Step 3 Execution And Retrieval\n",
    "- Notebook run: set `RUN_STEP3_PIPELINE = True` in the first Step 3 code cell and execute it once.\n",
    "- CLI run: `PYTHONPATH=src:src/elias python -m elias_models.cli surrogate-run --run-id <run_id> --csv-path data/participants.csv --n-surrogates-per-model <N> --seed <S> --output-root data/elias`\n",
    "- Show one run: `PYTHONPATH=src:src/elias python -m elias_models.cli surrogate-show --run-id <run_id> --output-root data/elias`\n",
    "- List runs: `PYTHONPATH=src:src/elias python -m elias_models.cli surrogate-list --output-root data/elias`\n",
    "- Persistent outputs: `data/elias/surrogate_recovery/runs/<run_id>/tables/`\n",
    "- Cross-session loading in notebook: `load_step3_run(run_id, output_root=\"data/elias\")`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 — BUILD ONE CANONICAL PIPELINE CONFIG AND OPTIONALLY RUN IT\n",
    "\n",
    "from elias_models import build_step3_pipeline_config, run_step3_pipeline\n",
    "\n",
    "STEP3_RUN_ID = \"step3_surrogate_recovery_v1\"\n",
    "STEP3_OUTPUT_ROOT = REPO_ROOT / \"data\" / \"elias\"\n",
    "\n",
    "# One canonical Step 3 configuration shared by notebook and CLI.\n",
    "STEP3_CONFIG = build_step3_pipeline_config(\n",
    "    candidate_models=(\"cont_threshold\", \"cont_asymptote\", \"ddm_dnm\"),\n",
    "    n_surrogates_per_model=20,\n",
    "    surrogate_n_draws_per_trial=128,\n",
    "    fit_n_starts=4,\n",
    "    fit_n_iterations=8,\n",
    "    fit_n_sims_per_trial=150,\n",
    "    dt_ms=float(DT),\n",
    "    max_duration_ms=float(T_MAX),\n",
    "    random_seed=int(SEED),\n",
    "    soft_gate_joint_diag_min=0.60,\n",
    "    soft_gate_param_median_r_min=0.30,\n",
    ")\n",
    "\n",
    "cli_models = \",\".join(STEP3_CONFIG[\"candidate_models\"])\n",
    "cli_cmd = (\n",
    "    f\"PYTHONPATH=src:src/elias python -m elias_models.cli surrogate-run \"\n",
    "    f\"--run-id {STEP3_RUN_ID} \"\n",
    "    f\"--csv-path data/participants.csv \"\n",
    "    f\"--candidate-models {cli_models} \"\n",
    "    f\"--n-surrogates-per-model {STEP3_CONFIG['n_surrogates_per_model']} \"\n",
    "    f\"--surrogate-n-draws-per-trial {STEP3_CONFIG['surrogate_n_draws_per_trial']} \"\n",
    "    f\"--fit-n-starts {STEP3_CONFIG['fit_n_starts']} \"\n",
    "    f\"--fit-n-iterations {STEP3_CONFIG['fit_n_iterations']} \"\n",
    "    f\"--fit-n-sims-per-trial {STEP3_CONFIG['fit_n_sims_per_trial']} \"\n",
    "    f\"--dt-ms {STEP3_CONFIG['dt_ms']} \"\n",
    "    f\"--max-duration-ms {STEP3_CONFIG['max_duration_ms']} \"\n",
    "    f\"--seed {STEP3_CONFIG['random_seed']} \"\n",
    "    f\"--output-root {STEP3_OUTPUT_ROOT}\"\n",
    ")\n",
    "\n",
    "print(\"Step 3 run id:\", STEP3_RUN_ID)\n",
    "print(\"Step 3 output root:\", STEP3_OUTPUT_ROOT)\n",
    "print(\"\\nStep 3 canonical config:\")\n",
    "print(STEP3_CONFIG)\n",
    "print(\"\\nEquivalent CLI command:\")\n",
    "print(cli_cmd)\n",
    "\n",
    "# Keep False during code editing; switch to True on the faster machine to execute the full run.\n",
    "RUN_STEP3_PIPELINE = False\n",
    "\n",
    "if RUN_STEP3_PIPELINE:\n",
    "    step3_run_output = run_step3_pipeline(\n",
    "        df_all,\n",
    "        run_id=STEP3_RUN_ID,\n",
    "        output_root=STEP3_OUTPUT_ROOT,\n",
    "        config=STEP3_CONFIG,\n",
    "        overwrite=False,\n",
    "    )\n",
    "    print(\"\\nStep 3 pipeline run completed.\")\n",
    "    print(\"Run directory:\", step3_run_output[\"run_dir\"])\n",
    "    print(\"Soft-gate status:\", step3_run_output[\"manifest\"][\"soft_gate\"][\"overall_status\"])\n",
    "else:\n",
    "    step3_run_output = None\n",
    "    print(\"\\nStep 3 pipeline execution skipped. Set RUN_STEP3_PIPELINE=True to execute.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "- [ ] Refit all candidate models on each surrogate dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 — LOAD PERSISTED REFIT RESULTS AND DISPLAY FIT DIAGNOSTICS\n",
    "\n",
    "from elias_models import load_step3_run\n",
    "\n",
    "required_names = [\"STEP3_RUN_ID\", \"STEP3_OUTPUT_ROOT\", \"STEP3_CONFIG\"]\n",
    "missing_names = [name for name in required_names if name not in globals()]\n",
    "if missing_names:\n",
    "    raise ValueError(\n",
    "        f\"Missing required Step 3 configuration variables: {missing_names}. \"\n",
    "        \"Run the first Step 3 code cell first.\"\n",
    "    )\n",
    "\n",
    "step3_loaded_run = load_step3_run(\n",
    "    run_id=STEP3_RUN_ID,\n",
    "    output_root=STEP3_OUTPUT_ROOT,\n",
    ")\n",
    "\n",
    "step3_fit_results = step3_loaded_run[\"tables\"].get(\"fit_results\", pd.DataFrame())\n",
    "if step3_fit_results.empty:\n",
    "    raise ValueError(\n",
    "        \"fit_results table is empty. Execute Step 3 pipeline first \"\n",
    "        \"(notebook RUN_STEP3_PIPELINE=True or CLI surrogate-run).\"\n",
    "    )\n",
    "\n",
    "step3_fit_summary_table = (\n",
    "    step3_fit_results.groupby([\"generating_model_name\", \"candidate_model_name\"], as_index=False)\n",
    "    .agg(\n",
    "        n_rows=(\"joint_score\", \"size\"),\n",
    "        joint_min=(\"joint_score\", \"min\"),\n",
    "        joint_median=(\"joint_score\", \"median\"),\n",
    "    )\n",
    "    .sort_values([\"generating_model_name\", \"joint_median\", \"candidate_model_name\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "step3_joint_scores_finite = bool(np.isfinite(step3_fit_results[\"joint_score\"]).all())\n",
    "expected_rows = int(\n",
    "    len(STEP3_CONFIG[\"candidate_models\"])\n",
    "    * int(STEP3_CONFIG[\"n_surrogates_per_model\"])\n",
    "    * len(STEP3_CONFIG[\"candidate_models\"])\n",
    ")\n",
    "actual_rows = int(len(step3_fit_results))\n",
    "\n",
    "print(\"Loaded run directory:\", step3_loaded_run[\"run_dir\"])\n",
    "print(\n",
    "    f\"Refit rows: {actual_rows} (expected {expected_rows}) | \"\n",
    "    f\"All joint scores finite: {step3_joint_scores_finite}\"\n",
    ")\n",
    "\n",
    "print(\"\\nStep 3 chunk-2 diagnostic summary:\")\n",
    "display(step3_fit_summary_table)\n",
    "\n",
    "print(\"\\nStep 3 chunk-2 fit results preview:\")\n",
    "display(step3_fit_results.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "- [ ] Build model-recovery matrix and parameter-recovery summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 — LOAD RECOVERY MATRICES AND PARAMETER-RECOVERY SUMMARIES\n",
    "\n",
    "from elias_models import load_step3_run\n",
    "\n",
    "if \"step3_loaded_run\" not in globals() or step3_loaded_run is None:\n",
    "    step3_loaded_run = load_step3_run(\n",
    "        run_id=STEP3_RUN_ID,\n",
    "        output_root=STEP3_OUTPUT_ROOT,\n",
    "    )\n",
    "\n",
    "step3_model_recovery_joint_counts = step3_loaded_run[\"tables\"].get(\n",
    "    \"model_recovery_joint_counts\",\n",
    "    pd.DataFrame(),\n",
    ")\n",
    "step3_model_recovery_joint_rates = step3_loaded_run[\"tables\"].get(\n",
    "    \"model_recovery_joint_rates\",\n",
    "    pd.DataFrame(),\n",
    ")\n",
    "step3_model_recovery_bic_counts = step3_loaded_run[\"tables\"].get(\n",
    "    \"model_recovery_bic_counts\",\n",
    "    pd.DataFrame(),\n",
    ")\n",
    "step3_model_recovery_bic_rates = step3_loaded_run[\"tables\"].get(\n",
    "    \"model_recovery_bic_rates\",\n",
    "    pd.DataFrame(),\n",
    ")\n",
    "step3_parameter_recovery_summary = step3_loaded_run[\"tables\"].get(\n",
    "    \"parameter_recovery_summary\",\n",
    "    pd.DataFrame(),\n",
    ")\n",
    "\n",
    "print(\"Step 3 chunk-3 model recovery (joint counts):\")\n",
    "display(step3_model_recovery_joint_counts)\n",
    "\n",
    "print(\"\\nStep 3 chunk-3 model recovery (joint rates):\")\n",
    "display(step3_model_recovery_joint_rates)\n",
    "\n",
    "print(\"\\nStep 3 chunk-3 model recovery (BIC counts):\")\n",
    "display(step3_model_recovery_bic_counts)\n",
    "\n",
    "print(\"\\nStep 3 chunk-3 model recovery (BIC rates):\")\n",
    "display(step3_model_recovery_bic_rates)\n",
    "\n",
    "print(\"\\nStep 3 chunk-3 parameter-recovery summary:\")\n",
    "display(step3_parameter_recovery_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "- [ ] Apply soft-gate interpretation: if recovery is weak, continue but downgrade winner claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 — LOAD SOFT-GATE SUMMARY AND PRINT INTERPRETATION\n",
    "\n",
    "from elias_models import load_step3_run\n",
    "\n",
    "if \"step3_loaded_run\" not in globals() or step3_loaded_run is None:\n",
    "    step3_loaded_run = load_step3_run(\n",
    "        run_id=STEP3_RUN_ID,\n",
    "        output_root=STEP3_OUTPUT_ROOT,\n",
    "    )\n",
    "\n",
    "step3_soft_gate_summary = step3_loaded_run[\"tables\"].get(\"soft_gate_summary\", pd.DataFrame())\n",
    "step3_soft_gate_status = step3_loaded_run[\"manifest\"].get(\"soft_gate\", {}).get(\n",
    "    \"overall_status\",\n",
    "    \"unknown\",\n",
    ")\n",
    "\n",
    "print(\"Step 3 chunk-4 soft-gate summary:\")\n",
    "display(step3_soft_gate_summary)\n",
    "\n",
    "if step3_soft_gate_status == \"pass\":\n",
    "    print(\"\\nSoft-gate interpretation: pass. Recovery quality supports stronger model-winner claims.\")\n",
    "elif step3_soft_gate_status == \"caution\":\n",
    "    print(\"\\nSoft-gate interpretation: caution. Winner claims should be qualified with recovery limits.\")\n",
    "elif step3_soft_gate_status == \"weak\":\n",
    "    print(\"\\nSoft-gate interpretation: weak. Winner claims should be downgraded and treated as exploratory.\")\n",
    "else:\n",
    "    print(\"\\nSoft-gate interpretation: unknown. Inspect run artifacts and thresholds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## STEP 4) FIT MODEL TO PARTICIPANT DATA — LOCK + CHECKLIST\n",
    "\n",
    "### Locked evaluation protocol\n",
    "- [ ] Fit on TRAIN only and evaluate on TEST only.\n",
    "- [ ] Use one optimizer protocol across models (multi-start count, convergence, iterations, seed policy).\n",
    "- [ ] Compute per participant: TEST joint total, blockwise consistency, secondary choice/RT totals.\n",
    "- [ ] Apply locked participant-level and group-level winner rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4 — PARTICIPANT FITTING AND TEST EVALUATION IMPLEMENTATION (PENDING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## STEP 5) LATENT VARIABLE ANALYSIS AND REPORTING — LOCK + CHECKLIST\n",
    "\n",
    "### Locked reporting requirements\n",
    "- [ ] Run posterior predictive checks per participant/block.\n",
    "- [ ] Run change-point/hazard signature checks.\n",
    "- [ ] Report interpretable latent-variable trajectories/quantities.\n",
    "- [ ] Apply recovery-aware final conclusions and include hazard-input caveat sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5 — LATENT-VARIABLE ANALYSIS AND REPORTING IMPLEMENTATION (PENDING)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
